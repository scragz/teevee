<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<!DOCTYPE genjit SYSTEM "file:genjit.dtd">
<genjit>
	<title>tv.core</title>
	<description>GPU processing: Scroll, Warp, Smear, Edge effects</description>
	<inlets>
		<inlet id="0" name="in1" type="texture" comment="Feedback texture" />
	</inlets>
	<outlets>
		<outlet id="0" name="out1" type="texture" />
	</outlets>
	<params>
		<param id="0" name="scroll_speed" type="float" default="0.01" min="0" max="1" />
		<param id="1" name="zoom" type="float" default="1" min="0.25" max="4" />
		<param id="2" name="rotation" type="float" default="0" min="-3.14159" max="3.14159" />
		<param id="3" name="smear" type="float" default="0" min="0" max="1" />
		<param id="4" name="edge_amount" type="float" default="0" min="0" max="1" />
		<param id="5" name="warp_x" type="float" default="0" min="-1" max="1" />
		<param id="6" name="warp_y" type="float" default="0" min="-1" max="1" />
	</params>
	<code><![CDATA[
// History for feedback - stores previous output frame
History feedback_frame(0);

// Get normalized coordinates
uv = norm;
center = vec(0.5, 0.5);

// Sample input texture at current position (the audio-encoded data)
input_color = sample(in1, uv);

// Center the UVs for rotation/zoom (for feedback sampling)
uv_centered = uv - center;

// Apply rotation
cos_r = cos(rotation);
sin_r = sin(rotation);
uv_rotated = vec(
    uv_centered.x * cos_r - uv_centered.y * sin_r,
    uv_centered.x * sin_r + uv_centered.y * cos_r
);

// Apply zoom
uv_zoomed = uv_rotated / zoom;

// Apply warp (barrel/pincushion distortion)
dist = length(uv_zoomed);
warp_factor = 1.0 + dist * dist * (warp_x + warp_y * dist);
uv_warped = uv_zoomed * warp_factor;

// Un-center and apply scroll
uv_feedback = uv_warped + center;
uv_feedback.y = uv_feedback.y - scroll_speed;

// Wrap coordinates for feedback sampling
uv_feedback = wrap(uv_feedback, 0, 1);

// Sample the feedback (previous frame with transforms applied)
feedback_color = sample(feedback_frame, uv_feedback);

// Edge detection on feedback (Sobel-like)
texel = 1.0 / dim;
left = sample(feedback_frame, uv_feedback + vec(-texel.x, 0));
right = sample(feedback_frame, uv_feedback + vec(texel.x, 0));
up = sample(feedback_frame, uv_feedback + vec(0, -texel.y));
down = sample(feedback_frame, uv_feedback + vec(0, texel.y));

edge_h = abs(left - right);
edge_v = abs(up - down);
edge = (edge_h + edge_v) * 0.5;

// Mix edge detection into feedback
feedback_with_edge = mix(feedback_color, feedback_color + edge, edge_amount);

// Blend input with processed feedback (smear controls feedback amount)
// At smear=0: pure input, at smear=1: pure feedback
output = mix(input_color, feedback_with_edge, smear);

// Store output for next frame's feedback
feedback_frame = output;

// Output
out1 = output;
]]></code>
</genjit>
